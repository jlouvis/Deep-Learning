{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder (downsampling)\n",
    "        # input size: (1, 501, 501)\n",
    "        self.e11 = Conv2d(1, 64, kernel_size=3, padding=1) # output: (64, 499, 499)\n",
    "        self.e12 = Conv2d(64, 64, kernel_size=3, padding=1) # output: (64, 497, 497)\n",
    "        self.pool1 = MaxPool2d(kernel_size=2, stride=2) # output: (64, 249, 249)\n",
    "\n",
    "        # input size: (64, 249, 249)\n",
    "        self.e21 = Conv2d(64, 128, kernel_size=3, padding=1) # output: (128, 247, 247)\n",
    "        self.e22 = Conv2d(128, 128, kernel_size=3, padding=1) # output: (128, 245, 245)\n",
    "        self.pool2 = MaxPool2d(kernel_size=2, stride=2) # output: (128, 122, 122)\n",
    "\n",
    "        # input size: (128, 122, 122)\n",
    "        self.e31 = Conv2d(128, 256, kernel_size=3, padding=1) # output: (256, 120, 120)\n",
    "        self.e32 = Conv2d(256, 256, kernel_size=3, padding=1) # output: (256, 118, 118)\n",
    "        self.pool3 = MaxPool2d(kernel_size=2, stride=2) # output: (256, 59, 59)\n",
    "\n",
    "        # input size: (256, 59, 59)\n",
    "        self.e41 = Conv2d(256, 512, kernel_size=3, padding=1) # output: (512, 57, 57)\n",
    "        self.e42 = Conv2d(512, 512, kernel_size=3, padding=1) # output: (512, 55, 55)\n",
    "        self.pool4 = MaxPool2d(kernel_size=2, stride=2) # output: (512, 27, 27)\n",
    "\n",
    "        # input size: (512, 27, 27)\n",
    "        self.e51 = Conv2d(512, 1024, kernel_size=3, padding=1) # output: (1024, 25, 25)\n",
    "        self.e52 = Conv2d(1024, 1024, kernel_size=3, padding=1) # output: (1024, 23, 23)\n",
    "\n",
    "        # Decoder (upsampling)\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.d11 = Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.d12 = Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        \n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.d21 = Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.d22 = Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.d31 = Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.d32 = Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.d41 = Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.d42 = Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Output layer\n",
    "        self.outconv = Conv2d(64, n_class, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        xe11 = relu(self.e11(x))\n",
    "        xe12 = relu(self.e12(xe11))\n",
    "        xp1 = self.pool1(xe12)\n",
    "\n",
    "        xe21 = relu(self.e21(xp1))\n",
    "        xe22 = relu(self.e22(xe21))\n",
    "        xp2 = self.pool2(xe22)\n",
    "\n",
    "        xe31 = relu(self.e31(xp2))\n",
    "        xe32 = relu(self.e32(xe31))\n",
    "        xp3 = self.pool3(xe32)\n",
    "\n",
    "        xe41 = relu(self.e41(xp3))\n",
    "        xe42 = relu(self.e42(xe41))\n",
    "        xp4 = self.pool4(xe42)\n",
    "\n",
    "        xe51 = relu(self.e51(xp4))\n",
    "        xe52 = relu(self.e52(xe51))\n",
    "\n",
    "        # Decoder\n",
    "        xu1 = self.upconv1(xe52)\n",
    "        xu11 = torch.cat([xu1, xe42], dim=1)\n",
    "        xd11 = relu(self.d11(xu11))\n",
    "        xd12 = relu(self.d12(xd11))\n",
    "\n",
    "        xu2 = self.upconv2(xd12)\n",
    "        #xu22 = torch.cat([xu2, xe32], dim=1)\n",
    "        xu22 = torch.cat([xu2, xe32[:, :, :xu2.size(2), :xu2.size(3)]], dim=1)\n",
    "        xd21 = relu(self.d21(xu22))\n",
    "        xd22 = relu(self.d22(xd21))\n",
    "\n",
    "        xu3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xu3, xe22[:, :, :xu3.size(2), :xu3.size(3)]], dim=1)\n",
    "        xd31 = relu(self.d31(xu33))\n",
    "        xd32 = relu(self.d32(xd31))\n",
    "\n",
    "        xu4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xu4, xe12[:, :, :xu4.size(2), :xu4.size(3)]], dim=1)\n",
    "        xd41 = relu(self.d41(xu44))\n",
    "        xd42 = relu(self.d42(xd41))\n",
    "\n",
    "        # Output layer\n",
    "        out = self.outconv(xd42)\n",
    "\n",
    "        return out\n",
    "\n",
    "net = Unet(3) # 3 classes\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "\n",
    "device = torch.device('cpu')  # use cuda or cpu\n",
    "net.to(device)\n",
    "print(net)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
